{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;}
{\colortbl;\red255\green255\blue255;\red35\green255\blue6;\red251\green0\blue7;\red253\green139\blue9;
\red0\green0\blue0;\red25\green60\blue255;\red251\green0\blue7;\red25\green60\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c100000\c0;\cssrgb\c100000\c12195\c0;\cssrgb\c100000\c61456\c0;
\cssrgb\c0\c1\c1;\cssrgb\c12594\c35385\c100000;\cssrgb\c100000\c12195\c0;\cssrgb\c12594\c35385\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 12/30/19\
AA Data Structures/Algorithms Notes, I Complexity Analysis\

\f1\b \ul 1. Big O Functions
\f0\b0 \ulnone  (from small to large growth) \
x = constant, n = input size\
	\cf2 Constant\cf0 		f(n) = 1		\cf3 O(1)\cf0 \
	\cf2 Logarithmic\cf0 	f(n) = log(n)	\cf3 O( logN )\cf0 \
	\cf2 Linear\cf0 		f(n) = n		\cf3 O(N)\cf0 \
	\cf4 Loglinear\cf0 		f(n) =  n log(n)	\cf3 O( N * logN )\cf0 \
\cf5 	\cf4 Polynomial\cf5 		f(n) = n^x		O(N^x)	Ex.\cf3  N^2\cf5 \
	\cf3 Exponential\cf5 	f(n) = x^n		O(x^N)	Ex. \cf3 2^N\cf5 		\
	\cf3 Factorial\cf5 		f(n) = n!		\cf3 O(N!)\cf0 \
\
\

\f1\b \ul 2. Key Takeaways
\f0\b0 \ulnone \
- We are interested in the behavior of a function as the input size approaches infinity\
- Big O usually describes the worst case scenario (upper bound)\
\
\

\f1\b \ul 3. Logarithm
\f0\b0 \ulnone \
Logarithm = exponent\
Logarithmic form			Exponential Form\
Log base 2 of 8 = 3		->  	2^3 = 8\
Log2 of 8 = 3\
- \cf6 every time we double the size of the input, we only require one additional computation/step\cf0 . A large input size will only increase the number of steps by a relatively small amount. Example is the binary search algorithm\
\
\

\f1\b \ul 4. Rules for Big O
\f0\b0 \ulnone \
1) \cf6 Drop constants when it comes to products\cf0 \
- \cf6 Apply product rule before sum rule\cf0 \
	Ex. 5n^2\
	drop 5 so Big O 	=> O(n^2)\
	Ex. 12		=> O(1)\
\
2)\cf6  If the function is a sum, keep the term with the dominant/largest growth rate\cf0 \
	Ex. \
	n^3 + n^2 + n	=> O(N^
\fs30 3
\fs28 )\
\
	Ex. \
	log(n) + 2^n	=>  O(2^N)\
\
\
\

\f1\b \ul 5. Big O Code Samples (see video 4, 5):
\f0\b0 \ulnone \
Logarithmic- O(logN). \
another \cf6 example is the binary search algorithm\cf0 \
\cf3 	function logarithmic(n) \{\
		if (n <= 1) return;\
		logarithmic(n / 2);\
	\}\cf0 \
\
\
LogLinear- N LogN\
Another \cf6 example is the Merge Sort algorithm\cf0 \
	Ex. log2 of 8\
\cf3 	function loglinear(n) \{\
		if (n <= 1) return;\
		for (let i = 1; i <= n; i++) \{\
		\}\
		loglinear( n/2 );\
		loglinear( n/2 );\
	\}\cf0 \
- ? Still don\'92t get this\
- ? Why isn\'92t above exponential since there are 2 recursive calls?\
	- because \cf6 number of times we branch is not going to be fixed (halves)\cf0 \
\
\
Exponential (video 5)\
- typically recursive functions\
- the base is usually the number of recursive calls\
\cf6 - the number of times we branch is fixed!!\cf0  \
- another example are functions that \cf6 generate all subsets/combinations of elements\
in an array\cf0 . Order does matter\
Ex. 2 recursive calls => O( 2^n )\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf7 	function exponential(n) \{\
		if (n <= 1) return;\
		exponential( n - 1 );\
		exponential( n - 1 );\
	\}\cf0 \
Ex. 3 recursive calls => O( 3^n )\
\cf7 	function exponential(n) \{\
		if (n <= 1) return;\
		exponential( n - 1 );\
		exponential( n - 1 );\
		exponential( n - 1 );\
	\}\cf0 \
\
\
Factorial\
- Ex. functions that \cf8 generate all permutations of elements\
in an array\cf0 . Order does matter\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}